# GDA-Class_Collapse - √âtude du Collapse de Classes avec Apprentissage Contrastif

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.9+-red.svg)](https://pytorch.org/)
[![Matplotlib](https://img.shields.io/badge/Matplotlib-3.5+-orange.svg)](https://matplotlib.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## üéØ Overview

Ce projet √©tudie le ph√©nom√®ne de "class collapse" dans l'apprentissage contrastif, un probl√®me o√π les repr√©sentations apprises par un mod√®le s'effondrent en un seul point ou cluster, perdant ainsi leur capacit√© discriminative. L'√©tude utilise des techniques d'apprentissage contrastif avec diff√©rents param√®tres alpha pour analyser et visualiser ce comportement.

## üöÄ Key Features

### Apprentissage Contrastif
- **Contrastive Loss with Alpha** - Fonction de perte contrastive param√©trable
- **Temperature Scaling** - Contr√¥le de la temp√©rature pour la similarit√©
- **Normalization** - Normalisation L2 des repr√©sentations
- **Positive/Negative Pairs** - Gestion des paires positives et n√©gatives

### √âtude du Class Collapse
- **Param√®tre Alpha** - Contr√¥le du degr√© de collapse (0.0 √† 1.0)
- **Visualisation Interactive** - Comparaison des donn√©es originales vs apprises
- **Analyse Comparative** - √âtude de l'impact de diff√©rents param√®tres
- **M√©triques de Collapse** - Mesures quantitatives du ph√©nom√®ne

### Datasets et Exp√©rimentations
- **Dataset Synth√©tique** - G√©n√©ration de donn√©es multi-classes
- **House Dataset** - Dataset sp√©cialis√© pour l'√©tude
- **Stratification** - Donn√©es stratifi√©es par classes et strates
- **Reproductibilit√©** - Seeds fixes pour la reproductibilit√©

## üìÅ Project Structure

```
GDA-Class_Collapse/
‚îú‚îÄ‚îÄ script.py                    # Script principal d'exp√©rimentation
‚îú‚îÄ‚îÄ train.py                     # Script d'entra√Ænement modulaire
‚îú‚îÄ‚îÄ dataset.py                   # G√©n√©ration et gestion des datasets
‚îú‚îÄ‚îÄ losses.py                    # Impl√©mentation des fonctions de perte
‚îú‚îÄ‚îÄ visualization.py             # Utilitaires de visualisation
‚îú‚îÄ‚îÄ outputs/                     # R√©sultats et visualisations
‚îÇ   ‚îú‚îÄ‚îÄ original_data_alpha_*.png    # Donn√©es originales par alpha
‚îÇ   ‚îî‚îÄ‚îÄ learned_representations_alpha_*.png  # Repr√©sentations apprises
‚îî‚îÄ‚îÄ README.md                    # Documentation du projet
```

## üõ†Ô∏è Installation

### Pr√©requis
- Python 3.8+
- PyTorch 1.9+
- NumPy
- Matplotlib
- Scikit-learn (optionnel)

### Installation des d√©pendances

```bash
# Cloner le repository
git clone https://github.com/arthurriche/GDA-Class_Collapse.git
cd GDA-Class_Collapse

# Installer les d√©pendances
pip install torch torchvision
pip install numpy
pip install matplotlib
pip install scikit-learn
```

## üìà Quick Start

### 1. Ex√©cution Rapide

```bash
# Lancer l'exp√©rimentation compl√®te
python script.py

# Ou utiliser le script modulaire
python train.py
```

### 2. Exp√©rimentation Interactive

```python
from script import train_model, create_dataset
import matplotlib.pyplot as plt

# Cr√©er un dataset
data, labels = create_dataset(num_classes=3, num_strata=2, num_samples=100)

# Entra√Æner avec diff√©rents alphas
alphas = [0.0, 0.25, 0.5, 0.75, 1.0]
for alpha in alphas:
    model, data, labels = train_model(alpha=alpha, num_epochs=100)
    # Visualiser les r√©sultats...
```

### 3. Analyse des R√©sultats

```python
# Les visualisations sont automatiquement sauvegard√©es dans outputs/
# Comparer les diff√©rents alphas pour observer le class collapse
```

## üßÆ Technical Implementation

### Contrastive Loss with Alpha

```python
class ContrastiveLossWithAlpha(nn.Module):
    def __init__(self, temperature=0.5, alpha=0.5):
        super().__init__()
        self.temperature = temperature
        self.alpha = alpha

    def forward(self, z_i, z_j):
        # Normalisation L2
        z_i = nn.functional.normalize(z_i, dim=1)
        z_j = nn.functional.normalize(z_j, dim=1)
        
        # Calcul de la matrice de similarit√©
        representations = torch.cat([z_i, z_j], dim=0)
        similarity_matrix = torch.matmul(representations, representations.T) / self.temperature
        
        # Gestion des paires positives/n√©gatives
        # ... logique de calcul de la perte
```

### Architecture du Mod√®le

```python
model = nn.Sequential(
    nn.Linear(2, 128),    # Couche d'entr√©e
    nn.ReLU(),            # Activation
    nn.Linear(128, 64)    # Couche de sortie (repr√©sentations)
)
```

### G√©n√©ration de Donn√©es

```python
def create_dataset(num_classes=3, num_strata=2, num_samples=100):
    data = []
    labels = []
    for class_id in range(num_classes):
        for stratum_id in range(num_strata):
            mean = np.random.rand(2) * (class_id + 1)
            points = mean + 0.1 * np.random.randn(num_samples, 2)
            data.append(points)
            labels += [class_id] * num_samples
    return torch.tensor(data, dtype=torch.float32), torch.tensor(labels)
```

## üìä Performance Analysis

### Impact du Param√®tre Alpha

| Alpha | Comportement | Collapse | S√©parabilit√© |
|-------|-------------|----------|--------------|
| 0.0   | Pas de collapse | Faible | √âlev√©e |
| 0.25  | Collapse partiel | Mod√©r√© | Mod√©r√©e |
| 0.5   | Collapse √©quilibr√© | Moyen | Moyenne |
| 0.75  | Collapse avanc√© | √âlev√© | Faible |
| 1.0   | Collapse total | Maximum | Minimale |

### M√©triques d'√âvaluation

- **Intra-class Variance** - Variance au sein des classes
- **Inter-class Distance** - Distance entre les classes
- **Collapse Ratio** - Ratio de collapse des repr√©sentations
- **Separability Score** - Score de s√©parabilit√© des classes

## üî¨ Advanced Features

### Analyse du Class Collapse

Le class collapse se produit quand :
- Les repr√©sentations d'une classe se concentrent en un point
- La variance intra-classe devient tr√®s faible
- Les classes perdent leur s√©parabilit√©

### Contr√¥le via Alpha

Le param√®tre alpha contr√¥le :
- **Intensit√© du collapse** - Plus alpha est √©lev√©, plus le collapse est prononc√©
- **Balance exploration/exploitation** - √âquilibre entre diversit√© et concentration
- **Robustesse des repr√©sentations** - Capacit√© de g√©n√©ralisation

### Visualisation Avanc√©e

- **Scatter Plots** - Visualisation 2D des repr√©sentations
- **Heatmaps** - Matrices de similarit√©
- **Trajectories** - √âvolution des repr√©sentations pendant l'entra√Ænement
- **Distribution Analysis** - Analyse des distributions de similarit√©

## üöÄ Applications

### Recherche en Deep Learning
- **√âtude des ph√©nom√®nes d'effondrement** - Compr√©hension des m√©canismes
- **Optimisation des fonctions de perte** - Am√©lioration des performances
- **Robustesse des mod√®les** - √âvaluation de la stabilit√©

### Applications Pratiques
- **Computer Vision** - Classification d'images robuste
- **NLP** - Repr√©sentations de texte stables
- **Recommendation Systems** - Embeddings robustes

## üìö Documentation Technique

### M√©canismes du Class Collapse

1. **Convergence Excessive** - Les repr√©sentations convergent trop fortement
2. **Perte de Diversit√©** - R√©duction de la variance intra-classe
3. **Effondrement Structurel** - Perte de la structure discriminative

### Strat√©gies de Mitigation

- **Regularization** - Techniques de r√©gularisation
- **Temperature Scaling** - Ajustement de la temp√©rature
- **Data Augmentation** - Augmentation des donn√©es
- **Architecture Modifications** - Modifications architecturales

### Hyperparam√®tres

- **Learning Rate** - 0.001 (Adam optimizer)
- **Temperature** - 0.5 (contr√¥le de la similarit√©)
- **Hidden Size** - 128 (taille des couches cach√©es)
- **Output Size** - 64 (dimension des repr√©sentations)

## ü§ù Contributing

1. Fork le repository
2. Cr√©er une branche feature (`git checkout -b feature/amazing-feature`)
3. Commit les changements (`git commit -m 'Add amazing feature'`)
4. Push vers la branche (`git push origin feature/amazing-feature`)
5. Ouvrir une Pull Request

## üìù License

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

## üë®‚Äçüíª Author

**Arthur Riche**
- LinkedIn: [Arthur Riche](https://www.linkedin.com/in/arthurriche/)
- Email: arthur.riche@example.com

## üôè Acknowledgments

- **√âquipe de Recherche** pour la supervision acad√©mique
- **Communaut√© PyTorch** pour les outils de deep learning
- **Contributeurs Open Source** pour les biblioth√®ques utilis√©es
- **Pairs de Recherche** pour les discussions et feedback

---

‚≠ê **Star ce repository si vous le trouvez utile !**

*Ce projet fournit une √©tude approfondie du ph√©nom√®ne de class collapse dans l'apprentissage contrastif, avec des outils de visualisation et d'analyse pour comprendre ce comportement critique.* 